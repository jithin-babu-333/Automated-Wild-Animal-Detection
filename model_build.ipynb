{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete build in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, MaxPool2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "labels = ['buffalo', 'elephant', 'monkey', 'tiger','wild boar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION\n",
    "# Balancing the no.of images to 300 in each class\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Count the number of images in each class\n",
    "#class_counts = {}\n",
    "#for class_name in os.listdir(base_dir):\n",
    "    class_path = os.path.join(base_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        class_count = len(os.listdir(class_path))\n",
    "        class_counts[class_name] = class_count\n",
    "\n",
    "# Create a directory to store the augmented images\n",
    "augmented_dir = os.path.join(base_dir, \"augmented\")\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "# Augment the images to reach the desired number of images per class\n",
    "for class_name, count in class_counts.items():\n",
    "    if count < desired_images_per_class:\n",
    "        class_dir = os.path.join(base_dir, class_name)\n",
    "        augmented_class_dir = os.path.join(augmented_dir, class_name)\n",
    "        os.makedirs(augmented_class_dir, exist_ok=True)\n",
    "\n",
    "        # Calculate the number of images to generate\n",
    "        num_augmented_images = desired_images_per_class - count\n",
    "\n",
    "        # Generate augmented images\n",
    "        for i in range(num_augmented_images):\n",
    "            # Get a random image from the class directory\n",
    "            image_file = os.listdir(class_dir)[i % count]\n",
    "            image_path = os.path.join(class_dir, image_file)\n",
    "\n",
    "            # Generate a new filename for the augmented image\n",
    "            augmented_image_file = f\"augmented_{i + 1}.jpg\"\n",
    "            augmented_image_path = os.path.join(augmented_class_dir, augmented_image_file)\n",
    "\n",
    "            # Copy and augment the image\n",
    "            shutil.copy(image_path, augmented_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Moving the augmented images to the original folders\n",
    "\n",
    "#original_dataset_dir = '/content/drive/MyDrive/data1'\n",
    "#augmented_dataset_dir = '/content/drive/MyDrive/data1/augmented'\n",
    "\n",
    "#for class_folder in labels:\n",
    "    augmented_class_folder = os.path.join(augmented_dataset_dir, class_folder)\n",
    "    original_class_folder = os.path.join(original_dataset_dir, class_folder)\n",
    "\n",
    "    # Move the augmented images to the original dataset class folder\n",
    "    for filename in os.listdir(augmented_class_folder):\n",
    "        source = os.path.join(augmented_class_folder, filename)\n",
    "        destination = os.path.join(original_class_folder, filename)\n",
    "        shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def count_images(folder_path, file_extensions=[\".jpg\", \".jpeg\", \".png\"]):\n",
    "    image_count = 0\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path) and os.path.splitext(file_name)[1].lower() in file_extensions:\n",
    "            image_count += 1\n",
    "    return image_count\n",
    "# Example usage\n",
    "folder_path = \"/content/drive/MyDrive/S6/Mini Project/Ajmal/data1/wild boar\"\n",
    "num_images = count_images(folder_path)\n",
    "print(\"Number of images:\", num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        i = 1\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                resized_arr = cv2.resize(img_arr, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "                data.append([resized_arr, class_num])\n",
    "                if(i%20 == 0):\n",
    "                  print(i,class_num)\n",
    "                i+=1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    print(\"Data loaded\")\n",
    "    print()\n",
    "    return np.array(data, dtype=object)\n",
    "\n",
    "dataset = get_training_data('/content/drive/MyDrive/Mini Project/data1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train, test, and validation sets\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.2\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Split the dataset into train and remaining (test + validation)\n",
    "train, remaining_data = train_test_split(dataset, train_size=train_ratio, random_state=42)\n",
    "\n",
    "# Split the remaining data into test and validation\n",
    "test, val = train_test_split(remaining_data, train_size=test_ratio/(test_ratio+val_ratio), random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Train data shape:\", train.shape)\n",
    "print(\"Test data shape:\", test.shape)\n",
    "print(\"Validation data shape:\", val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into features and labels\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "for feature, label in val:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "print(len(x_val))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test = np.array(x_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Resize data for deep learning\n",
    "x_train = x_train.reshape(-1, IMAGE_SIZE,IMAGE_SIZE, 3)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = x_val.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test = x_test.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=5)\n",
    "y_val = to_categorical(y_val, num_classes=5)\n",
    "y_test = to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1\n",
    "\n",
    "cnn=tf.keras.Sequential()\n",
    "cnn.add(resnet_model)\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,padding='same',strides=2,kernel_size=3,activation='relu',input_shape=(IMAGE_SIZE,IMAGE_SIZE,3)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Conv2D(filters=32, padding='same', strides=2, kernel_size=3, activation='relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Conv2D(filters=32, padding='same', strides=2, kernel_size=3, activation='relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(5, activation='softmax'))\n",
    "\n",
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "#model = tf.keras.Sequential()\n",
    "model.add(resnet_model)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model 3 without Resnet\n",
    "\n",
    "#model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "hist = cnn.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_val, y_val), callbacks=[reduce_lr, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \", cnn.evaluate(x_test, y_test)[0])\n",
    "print(\"Accuracy of the model is - \", cnn.evaluate(x_test, y_test)[1] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cnn.save(\"/content/drive/MyDrive/model/Model 4, with Resnet early stopping(81 acc,loss 0.67).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the current location and the destination location of the file\n",
    "source = '/content/Model P, without Resnet, Early Stop(85% acc).h5'\n",
    "destination = '/content/drive/MyDrive/S6/Mini Project/user'\n",
    "\n",
    "# Move the file to the new location\n",
    "shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "predictions = cnn.predict(x_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)  # Convert predictions to class labels\n",
    "true_labels = np.argmax(y_test, axis=1)  # Convert true labels to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(true_labels, predicted_labels, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm, cmap=\"Blues\", linecolor='black', linewidth=1, annot=True, fmt='', xticklabels=labels, yticklabels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(x_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], labels[i]))\n",
    "\n",
    "# Plot micro-average ROC curve\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='Micro-average ROC curve (area = %0.2f)' % roc_auc[\"micro\"], linestyle=':', linewidth=4)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "correct = np.nonzero(predicted_labels == true_labels)[0]\n",
    "incorrect = np.nonzero(predicted_labels != true_labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"No. of correctly predicted images: \", len(correct))\n",
    "print(\"No. of incorrectly predicted images: \", len(incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10, 8))\n",
    "fig.suptitle('Correctly Classified Images', fontsize=16)\n",
    "for i, idx in enumerate(correct[:6]):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    axes[row, col].imshow(x_test[idx])\n",
    "    axes[row, col].set_title(\"Predicted Class: {}\\nTrue Class: {}\".format(labels[predicted_labels[idx]], labels[true_labels[idx]]))\n",
    "    axes[row, col].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10, 8))\n",
    "fig.suptitle('Incorrectly Classified Images', fontsize=16)\n",
    "for i, idx in enumerate(incorrect[:6]):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    axes[row, col].imshow(x_test[idx])\n",
    "    axes[row, col].set_title(\"Predicted Class: {}\\nTrue Class: {}\".format(labels[predicted_labels[idx]], labels[true_labels[idx]]))\n",
    "    axes[row, col].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image = '/content/drive/MyDrive/Mini Project/data1/elephant/31c31736c6.jpg'\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img_arr = cv2.imread(image_path)\n",
    "    resized_arr = cv2.resize(img_arr, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    preprocessed_img = np.array(resized_arr) / 255.0\n",
    "    preprocessed_img = preprocessed_img.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    return preprocessed_img\n",
    "\n",
    "preprocessed_img = preprocess_image(image)\n",
    "prediction = cnn.predict(preprocessed_img)\n",
    "predicted_class = labels[np.argmax(prediction)]\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
